{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle competitions download -c santander-customer-transaction-prediction\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = os.path.join(\"datasets\", \"CustTransPrediction\")\n",
    "\n",
    "def load_data(filename, data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(data_path, filename)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# Create submission file with assigned predicted results from models\n",
    "def create_file_for_submission(filename, classifier_predictions):\n",
    "    \n",
    "    classifier_predictions = np.reshape(classifier_predictions, (classifier_predictions.shape[0], 1))\n",
    "    print(\"The reshape of Prediction numpy array : \", classifier_predictions.shape)\n",
    "\n",
    "    classifier_predicted_results = np.concatenate((iD_code, classifier_predictions), axis=1)\n",
    "    print(\"The concatenation of iD_code and Prediction numpy arrays  : \", classifier_predicted_results.shape)\n",
    "\n",
    "    print(\"For iD_codes : \", classifier_predicted_results[0:10,0])\n",
    "    print(\"The respective predicted results : \", classifier_predicted_results[0:10,1])\n",
    "    \n",
    "    # Create and overwrite existing file\n",
    "    with open('datasets/CustTransPrediction/' + filename, 'w') as writeFile:\n",
    "        filewriter = csv.writer(writeFile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow(['ID_code', 'target'])\n",
    "\n",
    "        iteration_range = classifier_predicted_results.shape[0]\n",
    "        for i in range(iteration_range):\n",
    "            filewriter.writerow([str(classifier_predicted_results[i,0]), str(classifier_predicted_results[i,1])])\n",
    "\n",
    "    writeFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the respective Train and Test data\n",
    "train_data = load_data(\"train.csv\")\n",
    "test_data = load_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 200), (200000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.drop([\"ID_code\", \"target\"], axis=1)\n",
    "y = train_data[\"target\"].copy()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_data.drop(['ID_code'], axis=1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "poly_scaler = Pipeline([\n",
    "    #(\"poly_features\", PolynomialFeatures(degree=2, include_bias=False)), # degree=10\n",
    "    (\"standard_scaler\", StandardScaler()) ])\n",
    "\n",
    "#X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
    "#X_val_poly_scaled = poly_scaler.transform(X_val)\n",
    "#X_test_poly_scaled = poly_scaler.transform(X_test)\n",
    "\n",
    "# If degree=3, there is a Memory Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Polynomial Features of degree 10, scaling will take more than 1 hour on a t2.instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = poly_scaler.fit_transform(X)\n",
    "y_train = y\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000, 200), (40000, 200), (160000,), (40000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train.shape is (200000, 200) and y_train.shape is (200000,)\n",
    "# ravel returns a contiguous flattened array giving (x,) instead of (x, 1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train.ravel(), test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=42, shuffle=True, tol=-inf, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_classifier = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42, class_weight='balanced')\n",
    "sgd_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_prediction = sgd_classifier.predict(X_val)\n",
    "accuracy_score(y_val, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6994374795151931"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit-Learn Cross-Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sgd_scores = cross_val_score(sgd_classifier, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "sgd_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale X_test and ready for predictions\n",
    "X_test_scaled = poly_scaler.fit_transform(X_test)\n",
    "\n",
    "sgd_predictions = sgd_classifier.predict(X_test_scaled)\n",
    "sgd_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from DataFrames to Numpy Array\n",
    "iD_code = test_data['ID_code'].values # get from DataFrame to Numpy Array\n",
    "iD_code = np.reshape(iD_code, (iD_code.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reshape of Prediction numpy array :  (200000, 1)\n",
      "The concatenation of iD_code and Prediction numpy arrays  :  (200000, 2)\n",
      "For iD_codes :  ['test_0' 'test_1' 'test_2' 'test_3' 'test_4' 'test_5' 'test_6' 'test_7'\n",
      " 'test_8' 'test_9']\n",
      "The respective predicted results :  [1 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "create_file_for_submission(\"sgd_classifier.csv\", sgd_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_classifier = LinearSVC(class_weight='balanced')\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8448374789356233"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Cross Validation to check the performance of Support Vector Machine\n",
    "svm_scores = cross_val_score(svm_classifier, X_train, y_train, cv=3)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_predictions = svm_classifier.predict(X_test_scaled)\n",
    "svm_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reshape of Prediction numpy array :  (200000, 1)\n",
      "The concatenation of iD_code and Prediction numpy arrays  :  (200000, 2)\n",
      "For iD_codes :  ['test_0' 'test_1' 'test_2' 'test_3' 'test_4' 'test_5' 'test_6' 'test_7'\n",
      " 'test_8' 'test_9']\n",
      "The respective predicted results :  [1 1 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "create_file_for_submission(\"svm_classifier.csv\", svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimators': [('sgd_classifier',\n",
       "   SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "                 early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                 l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "                 n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "                 random_state=42, shuffle=True, tol=-inf, validation_fraction=0.1,\n",
       "                 verbose=0, warm_start=False)),\n",
       "  ('svm_classifier',\n",
       "   LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "             intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "             multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "             verbose=0))],\n",
       " 'flatten_transform': True,\n",
       " 'n_jobs': None,\n",
       " 'voting': 'hard',\n",
       " 'weights': None,\n",
       " 'sgd_classifier': SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "               n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "               random_state=42, shuffle=True, tol=-inf, validation_fraction=0.1,\n",
       "               verbose=0, warm_start=False),\n",
       " 'svm_classifier': LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "           multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "           verbose=0),\n",
       " 'sgd_classifier__alpha': 0.0001,\n",
       " 'sgd_classifier__average': False,\n",
       " 'sgd_classifier__class_weight': 'balanced',\n",
       " 'sgd_classifier__early_stopping': False,\n",
       " 'sgd_classifier__epsilon': 0.1,\n",
       " 'sgd_classifier__eta0': 0.0,\n",
       " 'sgd_classifier__fit_intercept': True,\n",
       " 'sgd_classifier__l1_ratio': 0.15,\n",
       " 'sgd_classifier__learning_rate': 'optimal',\n",
       " 'sgd_classifier__loss': 'hinge',\n",
       " 'sgd_classifier__max_iter': 5,\n",
       " 'sgd_classifier__n_iter_no_change': 5,\n",
       " 'sgd_classifier__n_jobs': None,\n",
       " 'sgd_classifier__penalty': 'l2',\n",
       " 'sgd_classifier__power_t': 0.5,\n",
       " 'sgd_classifier__random_state': 42,\n",
       " 'sgd_classifier__shuffle': True,\n",
       " 'sgd_classifier__tol': -inf,\n",
       " 'sgd_classifier__validation_fraction': 0.1,\n",
       " 'sgd_classifier__verbose': 0,\n",
       " 'sgd_classifier__warm_start': False,\n",
       " 'svm_classifier__C': 1.0,\n",
       " 'svm_classifier__class_weight': 'balanced',\n",
       " 'svm_classifier__dual': True,\n",
       " 'svm_classifier__fit_intercept': True,\n",
       " 'svm_classifier__intercept_scaling': 1,\n",
       " 'svm_classifier__loss': 'squared_hinge',\n",
       " 'svm_classifier__max_iter': 1000,\n",
       " 'svm_classifier__multi_class': 'ovr',\n",
       " 'svm_classifier__penalty': 'l2',\n",
       " 'svm_classifier__random_state': None,\n",
       " 'svm_classifier__tol': 0.0001,\n",
       " 'svm_classifier__verbose': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('sgd_classifier', sgd_classifier),\n",
    "                ('svm_classifier', svm_classifier)], # svm_prob_classifier\n",
    "    voting='hard')\n",
    "\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "voting_classifier.get_params() # gives parameters of the VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8673812014423247"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier_scores = cross_val_score(voting_classifier, X_train, y_train, cv=3)\n",
    "voting_classifier_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier_predictions = voting_classifier.predict(X_test_scaled)\n",
    "\n",
    "voting_classifier_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reshape of Prediction numpy array :  (200000, 1)\n",
      "The concatenation of iD_code and Prediction numpy arrays  :  (200000, 2)\n",
      "For iD_codes :  ['test_0' 'test_1' 'test_2' 'test_3' 'test_4' 'test_5' 'test_6' 'test_7'\n",
      " 'test_8' 'test_9']\n",
      "The respective predicted results :  [1 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "create_file_for_submission(\"voting_classifier.csv\", voting_classifier_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissions\n",
    "- kaggle competitions submit -c santander-customer-transaction-prediction -f submission.csv -m \"Message\"\n",
    "- Submitted Public score of 0.516 at position 5,822\n",
    "- Submitted Public score of 0.593 at position 7,912\n",
    "- Submitted Public score of 0.749 at position 7,082 with balanced weight SVM Classifier on scaled test data having mean cv score of 84.645%.\n",
    "- Submitted Public score of 0.627 with Hard Voting Classifier having mean cv score of 89.886%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Random Forest Classifier\n",
    "\n",
    "- The cross validation will take more than 2.5 hours on t2 instance\n",
    "- It takes about 1.3 hours on GCP n1-standard-4 (4 vCPUs, 15 GB memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8995449996495875"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble Learning : Using Random Forest Classifier for prediction\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Using Cross Validation to check the performance of Random Forest Classifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train = poly_scaler.fit_transform(X)\n",
    "y_train = y\n",
    "forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_scores = cross_val_score(forest_classifier, X_train, y_train, n_jobs= 4, cv=10)\n",
    "forest_scores.mean()\n",
    "\n",
    "# Mean score of 89.954%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model fit and prediction also takes more than 0.5 hours on t2 instance\n",
    "- It also takes more than 0.5 hours on GCP n1-standard-4 (4 vCPUs, 15 GB memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions on the test set with Random Forest Classifier\n",
    "forest_classifier.fit(X_train, y_train)\n",
    "y_randomforest_predictions = forest_classifier.predict(X_test_scaled)\n",
    "\n",
    "y_randomforest_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_randomforest_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reshape of ID_code numpy array :  (200000, 1)\n",
      "The reshape of Random Forest Prediction numpy array :  (200000, 1)\n",
      "The concatenation of iD_code and Prediction numpy arrays  :  (200000, 2)\n",
      "For iD_codes :  ['test_0' 'test_1' 'test_2' 'test_3' 'test_4' 'test_5' 'test_6' 'test_7'\n",
      " 'test_8' 'test_9']\n",
      "The respective predicted results :  [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert from DataFrames to Numpy Array\n",
    "iD_code = test_data['ID_code'].values # get from DataFrame to Numpy Array\n",
    "iD_code = np.reshape(iD_code, (iD_code.shape[0], 1))\n",
    "print(\"The reshape of ID_code numpy array : \", iD_code.shape)\n",
    "\n",
    "y_randomforest_predictions = np.reshape(y_randomforest_predictions, (y_randomforest_predictions.shape[0], 1))\n",
    "print(\"The reshape of Random Forest Prediction numpy array : \", y_randomforest_predictions.shape)\n",
    "\n",
    "randomforest_predicted_results = np.concatenate((iD_code, y_randomforest_predictions), axis=1)\n",
    "print(\"The concatenation of iD_code and Prediction numpy arrays  : \", randomforest_predicted_results.shape)\n",
    "\n",
    "print(\"For iD_codes : \", randomforest_predicted_results[0:10,0])\n",
    "print(\"The respective predicted results : \", randomforest_predicted_results[0:10,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OSError: [Errno 12] Cannot allocate memory on t2 instance\n",
    "- It takes more than 1.3 hours on GCP n1-standard-4 (4 vCPUs, 15 GB memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Search the best combination of hyperparameter values\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kfold=10\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "                 \"max_features\": ['auto'], # [1, 3, 10],\n",
    "                 \"min_samples_split\": [2, 3, 10],\n",
    "                 \"min_samples_leaf\": [1, 3, 10],\n",
    "                 \"bootstrap\": [False],\n",
    "                 \"n_estimators\" :[100, 200, 500],\n",
    "                 \"criterion\": [\"gini\"]}\n",
    "\n",
    "# Tuning the param for GridSearch and performance has been increased to approx. 83.40% \n",
    "grid_search = GridSearchCV(forest_classifier, rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1) # without scoring parameter\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GridSearchCV to obtain final model with best estimator\n",
    "best_random_forest_classifier_model = grid_search.best_estimator_\n",
    "best_random_forest_classifier_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_classifier_scores = cross_val_score(best_random_forest_classifier_model, X_train, y_train,\n",
    "                                                       n_jobs= 4, cv=10)\n",
    "best_random_forest_classifier_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_randomforest_predictions = best_random_forest_classifier_model.predict(X_test_scaled)\n",
    "best_randomforest_predictions.shape\n",
    "\n",
    "create_file_for_submission(\"best_random_forest_classifier.csv\", best_randomforest_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent optimizing squared error cost with default learning rate and no regularization\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone\n",
    "\n",
    "sgd_regressor = SGDRegressor(max_iter=1, tol=-np.infty, penalty=None, eta0=0.0005,\n",
    "                             warm_start=True, learning_rate=\"constant\", random_state=42)\n",
    "\n",
    "num_epochs = 10\n",
    "minimum_val_error = float(\"inf\")\n",
    "best_epoch = None\n",
    "best_sgd_regressor_model = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # With warm_start=True and fit() is called, it will continue where it left off instead of restarting from scratch\n",
    "    sgd_regressor.fit(X_train, y_train)\n",
    "    y_val_predict = sgd_regressor.predict(X_val)\n",
    "\n",
    "    val_error = mean_squared_error(y_val, y_val_predict)\n",
    "    \n",
    "    print(\"Current epoch :\", epoch, \"with mse :\", val_error)\n",
    "\n",
    "    if val_error < minimum_val_error:\n",
    "        print(\"Epoch : \", epoch, \"with min mse :\", val_error)\n",
    "        minimum_val_error = val_error\n",
    "        best_epoch = epoch\n",
    "        best_sgd_regressor_model = clone(sgd_regressor)\n",
    "\n",
    "best_epoch, best_sgd_regressor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sgd_regressor_model.fit(X_train, y_train)\n",
    "sgd_predictions = best_sgd_regressor_model.predict(X_test_scaled)\n",
    "\n",
    "# Making predictions on the test set\n",
    "#y_sgd_predictions = best_sgd_regressor_model.predict(X_val_poly_scaled)\n",
    "\n",
    "sgd_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_score = best_sgd_regressor_model.score\n",
    "\n",
    "sgd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file_for_submission(\"sgd_regressor.csv\", sgd_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDRegressor' object has no attribute 'decision_function'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn Cross-Validation Prediction\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Compare classifiers by measuring the \"area under the curve\" (AUC) = 1 means perfect classifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_scores = cross_val_predict(best_sgd_regressor_model, X_train, y_train, cv=3, method=\"decision_function\")\n",
    "roc_auc_score(y_train, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
